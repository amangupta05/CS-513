{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a51ce082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics.cluster import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e21cce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset into a pandas DataFrame\n",
    "data = pd.read_csv(\"wisc_bc_ContinuousVar.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b332012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e59ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3be2dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target variables\n",
    "X = data.drop([\"id\", \"diagnosis\"], axis=1)\n",
    "y = data[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a5a6229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the feature variables\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630a3651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgglomerativeClustering()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying hierarchical clustering (hclust) with two clusters\n",
    "hclust = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
    "hclust.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6de933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding cluster labels to the dataset\n",
    "data['hclust_labels'] = hclust.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd71856f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hclust_labels    0    1\n",
      "diagnosis              \n",
      "B               27  330\n",
      "M              164   48\n"
     ]
    }
   ],
   "source": [
    "# Printing tabular results of hclust clusters against the diagnosis column\n",
    "print(pd.crosstab(index=data['diagnosis'], columns=data['hclust_labels']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53e064cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI Score for hclust: 0.5383388964592652\n"
     ]
    }
   ],
   "source": [
    "# Calculating ARI for hclust\n",
    "hclust_ari = adjusted_rand_score(data['diagnosis'], data['hclust_labels'])\n",
    "\n",
    "# Printing ARI for hclust\n",
    "print('ARI Score for hclust:', hclust_ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cde52508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying k-means clustering with two clusters\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa32fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding cluster labels to the dataset\n",
    "data['kmeans_labels'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1a30edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans_labels    0    1\n",
      "diagnosis              \n",
      "B                9  348\n",
      "M              180   32\n"
     ]
    }
   ],
   "source": [
    "# Printing tabular results of k-means clusters against the diagnosis column\n",
    "print(pd.crosstab(index=data['diagnosis'], columns=data['kmeans_labels']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9f9304b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI Score for k-means: 0.7301749027614344\n"
     ]
    }
   ],
   "source": [
    "# Calculating ARI for k-means\n",
    "kmeans_ari = adjusted_rand_score(data['diagnosis'], data['kmeans_labels'])\n",
    "\n",
    "# Printing ARI for k-means\n",
    "print('ARI Score for k-means:', kmeans_ari)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
